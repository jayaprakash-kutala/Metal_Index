{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for day of the week\n",
    "def weekday_check(timedelta,method):\n",
    "    date_now = date.today() + relativedelta(days=-timedelta)\n",
    "    three_months = date_now + relativedelta(months=-3)\n",
    "    week_number = date_now.weekday()\n",
    "    if week_number < 5:\n",
    "        date_now = date_now.strftime('%Y-%m-%d')\n",
    "        three_months = three_months.strftime('%Y-%m-%d')\n",
    "        dummy_variable = scrap_index(date_now,three_months,method)\n",
    "        return 0\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_index(date_now,three_months,method):\n",
    "\n",
    "    # extract data from .csv file\n",
    "    raw_data = pd.read_csv('metal_history_20181108.csv')\n",
    "    \n",
    "\n",
    "    # Mapping location with regions\n",
    "    mapping_dictionary = {'AL':'EAST COAST','CT':'EAST COAST','DE':'EAST COAST','FL':'EAST COAST','GA':'EAST COAST',\n",
    "    'IN':'EAST COAST','KY':'EAST COAST','ME':'EAST COAST','MD':'EAST COAST','MA':'EAST COAST',\n",
    "    'MI':'EAST COAST','MS':'EAST COAST','NH':'EAST COAST','NJ':'EAST COAST','NY':'EAST COAST',\n",
    "    'NC':'EAST COAST','OH':'EAST COAST','PA':'EAST COAST','RI':'EAST COAST','SC':'EAST COAST',\n",
    "    'TN':'EAST COAST','VT':'EAST COAST','VA':'EAST COAST','WV':'EAST COAST','AR':'MID WEST',\n",
    "    'IL':'MID WEST','IA':'MID WEST','KS':'MID WEST','LA':'MID WEST','MN':'MID WEST','MO':'MID WEST',\n",
    "    'NE':'MID WEST','ND':'MID WEST','OK':'MID WEST','SD':'MID WEST','TX':'MID WEST','WI':'MID WEST',\n",
    "    'AK':'WEST COAST','AZ':'WEST COAST','CA':'WEST COAST','CO':'WEST COAST','HI':'WEST COAST',\n",
    "    'ID':'WEST COAST','MT':'WEST COAST','NV':'WEST COAST','NM':'WEST COAST','OR':'WEST COAST',\n",
    "    'UT':'WEST COAST','WA':'WEST COAST','WY':'WEST COAST'}\n",
    "\n",
    "    raw_data['region'] = raw_data['state'].apply(lambda x: mapping_dictionary[x])\n",
    "\n",
    "    # convert unit TON to CWT of ferrous[unit standardization]\n",
    "    raw_data.price = raw_data.price.mask(raw_data.unit == 'TON',raw_data.price*0.056)\n",
    "    raw_data.unit = raw_data.unit.mask(raw_data.unit == 'TON','CWT')\n",
    "\n",
    "    # convert units: LB to CWT of ferrous[unit standardization]\n",
    "    raw_data.loc[(raw_data['commodity'] == 'Scrap Steel') & (raw_data['unit'] == 'LB'),'price'] = raw_data['price']*112\n",
    "    raw_data.loc[(raw_data['commodity'] == 'Scrap Steel') & (raw_data['unit'] == 'LB'),'unit'] = 'CWT'\n",
    "\n",
    "    # convert units: CWT to LB of Stainless Steel[unit standardization]\n",
    "    raw_data.loc[((raw_data['metalType'] == 'Non-Ferrous') & (raw_data['unit'] == 'CWT')) \n",
    "                 | ((raw_data['commodity'] == 'Scrap Stainless Steel') & (raw_data['unit'] == 'CWT')),\n",
    "                 'price'] = raw_data['price']*0.008929\n",
    "\n",
    "    raw_data.loc[((raw_data['metalType'] == 'Non-Ferrous') & (raw_data['unit'] == 'CWT'))\n",
    "                 | ((raw_data['commodity'] == 'Scrap Stainless Steel') & (raw_data['unit'] == 'CWT')),'unit'] = 'LB'\n",
    "\n",
    "    # Delete the data older than three months\n",
    "    raw_data['date'] = pd.to_datetime(raw_data['date']).dt.strftime('%Y-%m-%d')\n",
    "    raw_data = raw_data[(raw_data['date'] >= three_months) & (raw_data['date'] <= date_now)]\n",
    "    \n",
    "\n",
    "    # check the data for standard units\n",
    "    standard_units = ['LB','CWT','TON']\n",
    "    raw_data = raw_data[raw_data.unit.isin(standard_units)]\n",
    "\n",
    "    data_avail_dates = raw_data['date'].unique()\n",
    "    \n",
    "\n",
    "    # Average number of companies for each product on any day, in the past three months\n",
    "    locations_data = raw_data.groupby(['productId'])\n",
    "    average_locations_count = pd.DataFrame(columns = ['ProductId','Product','Commodity','Mean'])\n",
    "    iterative_index = 0\n",
    "    for productId,productId_group in locations_data:\n",
    "        average_product_count = (productId_group['product'].count()/len(data_avail_dates))\n",
    "        commodity_name = productId_group['commodity'].iloc[0]\n",
    "        product_name = productId_group['product'].iloc[0]\n",
    "        data = [productId,product_name,commodity_name,average_product_count]\n",
    "        average_locations_count.loc[iterative_index] = data\n",
    "        iterative_index +=1\n",
    "\n",
    "    # Filter metals based on threshold value\n",
    "    average_locations_count = average_locations_count[(average_locations_count['Mean'] > 10)]\n",
    "    filtered_metals = average_locations_count['ProductId']\n",
    "    raw_data = raw_data[raw_data.productId.isin(filtered_metals)]\n",
    "    average_locations_count.to_csv('Average_product_count.csv',index = 'False')\n",
    "\n",
    "    # Count the frequency of change in the prices for past three months\n",
    "    frequency_change_data = raw_data.groupby([\"location\",\"productId\"])\n",
    "    price_change_date_bycompany = pd.DataFrame(columns=['Location','date'])\n",
    "    iterative_index = 0\n",
    "    for loc_proId,loc_prodId_group in frequency_change_data:\n",
    "        price_difference =  loc_prodId_group['price'].diff().fillna(0)\n",
    "        price_change_dates = loc_prodId_group[(price_difference != 0)][['date']]\n",
    "        price_change_dates = pd.to_datetime(price_change_dates['date']).dt.strftime('%Y-%m-%d')\n",
    "        if(price_change_dates.empty == False):\n",
    "            last_price_change_date = price_change_dates.iloc[-1]\n",
    "        else:\n",
    "            last_price_change_date = three_months\n",
    "        data = [loc_proId[0],last_price_change_date]\n",
    "        price_change_date_bycompany.loc[iterative_index] = data\n",
    "        iterative_index +=1\n",
    "    latest_price_change = price_change_date_bycompany.groupby('Location')\n",
    "    for location,location_group in latest_price_change:\n",
    "        latest_price_change = location_group['date'].max()\n",
    "        raw_data.loc[(raw_data['location'] == location),'latest_price_change'] = latest_price_change\n",
    "\n",
    "    # Methodology Implementation    \n",
    "    raw_data = raw_data[raw_data['date'] == date_now]    \n",
    "    raw_data['date_now'] = date_now\n",
    "    raw_data['latest_price_change'] = pd.to_datetime(raw_data['latest_price_change'])\n",
    "    raw_data['date_now'] = pd.to_datetime(raw_data['date_now'])\n",
    "    raw_data['duration'] = (raw_data['date_now'] - raw_data['latest_price_change']).dt.days\n",
    "    raw_data.loc[(raw_data['duration'] == 0),'duration'] = 1\n",
    "    raw_data['duration'] = ((raw_data['duration']/14)+1).astype(int)\n",
    "    raw_data['weights'] = ((1/raw_data['duration'])**(1/method)).round(4)\n",
    "    raw_data['price-weights'] = (raw_data['price']*raw_data['weights'])\n",
    "\n",
    "    # Generate National Price Index\n",
    "    national_index_data = raw_data.groupby('productId')\n",
    "    national_index = pd.DataFrame(columns = ['ProductId','Product','Commodity','Region',\n",
    "                                             'Low','Mean','High','Price Unit'])\n",
    "    iterative_index = 0\n",
    "    for productId,productId_group in national_index_data:\n",
    "        price_quantile_10 = productId_group['price'].quantile(0.1)\n",
    "        price_quantile_90 = productId_group['price'].quantile(0.9)\n",
    "        productId_group = productId_group[(productId_group['price'] > price_quantile_10) \n",
    "                                      & (productId_group['price'] < price_quantile_90)]\n",
    "        mean = (productId_group['price-weights'].sum()/productId_group['weights'].sum())\n",
    "        low  = productId_group['price'].min()\n",
    "        high = productId_group['price'].max()\n",
    "        product_name = productId_group['product'].iloc[0]\n",
    "        commodity_name = productId_group['commodity'].iloc[0]\n",
    "        unit_name = productId_group['unit'].iloc[0]\n",
    "        region = 'National'\n",
    "        data = [productId,product_name,commodity_name,\n",
    "                region,low,mean,high,unit_name]\n",
    "        national_index.loc[iterative_index] = data\n",
    "        iterative_index +=1  \n",
    "    # national_index = national_index.round({'Low':2,'Mean':2,'High':2})\n",
    "    # national_index\n",
    "\n",
    "    # Regional Price Index\n",
    "    regional_index_data = raw_data.groupby(['productId','region'])\n",
    "    regional_index = pd.DataFrame(columns = ['ProductId','Product','Commodity','Region',\n",
    "                                             'Low','Mean','High','Price Unit'])\n",
    "    iterative_index = 0\n",
    "    for Id_region,Id_region_group in regional_index_data:\n",
    "        price_quantile_10 = Id_region_group['price'].quantile(0.1)\n",
    "        price_quantile_90 = Id_region_group['price'].quantile(0.9)\n",
    "        Id_region_group = Id_region_group[(Id_region_group['price'] > price_quantile_10) \n",
    "                                          & (Id_region_group['price'] < price_quantile_90)]\n",
    "        if(Id_region_group.empty == False):\n",
    "            mean = (Id_region_group['price-weights'].sum()/Id_region_group['weights'].sum())\n",
    "            low  = Id_region_group['price'].min()\n",
    "            high = Id_region_group['price'].max()\n",
    "            product_name = Id_region_group['product'].iloc[0]\n",
    "            commodity_name = Id_region_group['commodity'].iloc[0]\n",
    "            unit_name = Id_region_group['unit'].iloc[0]\n",
    "            region = Id_region[1]\n",
    "            data = [Id_region[0],product_name,commodity_name,\n",
    "                    region,low,mean,high,unit_name]\n",
    "            regional_index.loc[iterative_index] = data\n",
    "            iterative_index +=1\n",
    "            \n",
    "    regional_index = regional_index.sort_values(['Region','ProductId'])\n",
    "    scrap_metal_index = national_index.append(regional_index)\n",
    "    scrap_metal_index = scrap_metal_index.round({'Low':2,'Mean':2,'High':2})\n",
    "    \n",
    "    scrap_metal_index['date'] = date_now\n",
    "    scrap_metal_index = scrap_metal_index.rename(columns = {'Mean':'Index'})\n",
    "    \n",
    "    # export the index to excel\n",
    "    #scrap_metal_index = scrap_metal_index.drop(columns =['Low','High'])\n",
    "    file_name = \"Metal_Index-\" +'Method_'+ str(method) +'-' + str(date_now)+\".csv\"\n",
    "    scrap_metal_index.to_csv(file_name, index = False)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta = 34\n",
    "\n",
    "while(timedelta < 35):\n",
    "    temp1 = weekday_check(timedelta,method=1.0)\n",
    "    timedelta += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
